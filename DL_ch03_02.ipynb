{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_ch03_02.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO0/pIynfNRkiCLhZIkd/5M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jewookwak/AI/blob/master/DL_ch03_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 뉴스 기사 분류: 다중 분류 문제\n",
        "\n"
      ],
      "metadata": {
        "id": "t48NlK2zwR2N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 로이터 데이터셋\n",
        "- 1986년에 로이터에서 공개한 짧은 뉴스 기사와 토픽의 집합\n",
        "- 46개의 토픽이 있으며 어떤 토픽은 다른 것에 비해 데이터가 많음.\n",
        "- 각 토픽은 훈련 세트에 최소한 10개의 샘플을 가지고 있음."
      ],
      "metadata": {
        "id": "N3goWPEmw1sH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import reuters\n",
        "\n",
        "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words = 10000) # num_words =10000 -> 데이터에서 가장 자주 등장하는 단어 1만 개로 제한"
      ],
      "metadata": {
        "id": "5BmZLg48xCn4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_data))\n",
        "print(len(test_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gU1tUolGx4J8",
        "outputId": "8bdffba3-660a-4a21-c4d3-bcdd48f84d75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8982\n",
            "2246\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[10]  # 각 샘플은 정수 리스트 (단어 인덱스)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03h-MIdGyJjM",
        "outputId": "011411e8-dcc7-4ba9-f1ce-b7044944cbcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 245,\n",
              " 273,\n",
              " 207,\n",
              " 156,\n",
              " 53,\n",
              " 74,\n",
              " 160,\n",
              " 26,\n",
              " 14,\n",
              " 46,\n",
              " 296,\n",
              " 26,\n",
              " 39,\n",
              " 74,\n",
              " 2979,\n",
              " 3554,\n",
              " 14,\n",
              " 46,\n",
              " 4689,\n",
              " 4329,\n",
              " 86,\n",
              " 61,\n",
              " 3499,\n",
              " 4795,\n",
              " 14,\n",
              " 61,\n",
              " 451,\n",
              " 4329,\n",
              " 17,\n",
              " 12]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#로이터 데이터셋을 텍스트로 디코딩하기\n",
        "word_index = reuters.get_word_index()\n",
        "resverse_word_index = dict([(value,key) for (key, value) in word_index.items()])\n",
        "decoded_newswire = ' '.join([resverse_word_index.get(i-3,'?') for i in train_data[0]])"
      ],
      "metadata": {
        "id": "6UVWXTLeyMla"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels[10] # 샘플에 연결된 레이블은 토픽의 인덱스로 0과 45 사이의 정수"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dt00nGuyxVP",
        "outputId": "c575b3e2-505e-4537-e62c-f8d14ea3a08e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def vectorize_sequences(sequences, dimension= 10000):\n",
        "  results = np.zeros((len(sequences), dimension))\n",
        "  for i, sequence in  enumerate(sequences):\n",
        "    results[i, sequence] = 1.\n",
        "  return results\n",
        "x_train = vectorize_sequences(train_data)\n",
        "x_test = vectorize_sequences(test_data)"
      ],
      "metadata": {
        "id": "AZ0cuq0XzHs1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k = np.zeros((8982,10000))"
      ],
      "metadata": {
        "id": "JN9B_7jezMs-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_IS-0F3B0es4",
        "outputId": "1d72780d-b8f2-4e4b-8d56-9d5fa1ae5845"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8982, 10000)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k[0,1] = 1.\n",
        "k[1,245] = 1."
      ],
      "metadata": {
        "id": "9LlCg4x-0u0Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NCBs3vV1L07",
        "outputId": "f3638340-c1dd-4878-feae-3a20ef8237f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "원-핫 인코딩이 범주형 데이터에 널리 사용되기 때문에 범주형 인코딩(categorical encoding)이라고도 부릅니다."
      ],
      "metadata": {
        "id": "mpeZskFKz6iK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def to_one_hot(labels, dimension=46):\n",
        "  results = np.zeros((len(labels),dimension))\n",
        "  for i, label in enumerate(labels):\n",
        "    results[i, label] = 1.\n",
        "    return results\n",
        "\n",
        "one_hot_train_labels = to_one_hot(train_labels)\n",
        "one_hot_test_labels = to_one_hot(test_labels)"
      ],
      "metadata": {
        "id": "2ZOAPIjv1V2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "주석 \n",
        "- IMDB와 로이터 데이터셋은 미리 전체 데이터셋의 단어를 고유한 정수 인덱스로 바꾼 후에 훈련 데이터와 테스트 데이터로 나누어 놓은 것입니다. 일반적으로는 훈련 데이터에서 구축한 어휘 사전으로 테스트 세트를 변환합니다. 이렇게 하는 이유는 실전에서 샘플에 어떤 텍스트가 들어 있을지 알 수 없기 때문에 테스트 세트의 어휘를 이용하면 낙관적으로 테스트 세트를 평가하는 셈이 되기 때문입니다.\n",
        "- to_one_hot() 함수는 labels 매개변수를 제외하고는 앞에 정의된 vectorize_sequences()와 동일합니다. train_data와 test_data는 파이썬 리스트의 넘파이 배열이기 때문에 to_categorical() 함수를 사용하지 못합니다. x_train과 x_test의 크기는 각각 (8982,10000), (2246,10000)이 되고 one_hot_train_labels와 one_hot_test_labels의 크기는 각각 (8982, 46). (2246, 46)이 됩니다."
      ],
      "metadata": {
        "id": "VNP_uzqMkeXi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils.np_utils import to_categorical  #케라스 내장 함수\n",
        "\n",
        "one_hot_train_labels = to_categorical(train_labels)\n",
        "one_hot_test_labels = to_categorical(test_labels)"
      ],
      "metadata": {
        "id": "9HLevQQdlU-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 구성\n",
        "- 출력 클래스의 개수 : 2 -> 46  증가  \n",
        "- 출력 공간의 차원이 훨씬 커짐.\n",
        "- 정보의 병목 : 이전에 2class classification에서 처럼 Dense 층을 쌓으면, 각 층은 이전 층의 출력에서 제공한 정보만 사용할 수 있기 때문에 한 층이 분류 문제에 필요한 일부 정보를 누락하면 그다음 층에서 이를 복원할 방법이 없습니다.\n",
        "- 이전 예제에서 16차원을 가진 중간층을 사용했음. \n",
        "- 16차원 공간은 46개의 클래스를 구분하기에 너무 제약이 많기 때문에 병목 지점처럼 동작할 수 있음.\n",
        "- 따라서 더 규모가 큰 층을 사용 -> 64개 유닛 사용."
      ],
      "metadata": {
        "id": "oq06BJ9wmvYc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(64, activation='relu', input_shape = (10000,)))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(46, activation = 'softmax'))"
      ],
      "metadata": {
        "id": "ioIGEKF9ob7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 손실 함수 : categorical_crossentropy 사용 (multi class classification 문제이기 때문)\n",
        "- categorical_crossentropy는 두 확률 분포 사이의 거리를 측정\n",
        "- 여기에서는 네트워크가 출력한 확률 분포와 진짜 레이블의 분포 사이의 거리\n",
        "- 두 분포 사이의 거리를 최소화하면 진짜 레이블에 가능한 가까운 출력을 내도록 모델을 훈련하게 됨.\n"
      ],
      "metadata": {
        "id": "HI6jxZnoo4TC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "SqClHmEvp7dF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 훈련 검증\n",
        "훈련 데이터에서 1,000개의 샘플을 따로 떼어서 검증 세트로 사용함."
      ],
      "metadata": {
        "id": "XNQWj6mXqGhw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_val = x_train[:1000]\n",
        "partial_x_train = x_train[1000:]\n",
        "\n",
        "y_val = one_hot_train_labels[:1000]\n",
        "partial_y_train = one_hot_train_labels[1000:]"
      ],
      "metadata": {
        "id": "WtySDiyRqRyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "20번의 에포크로 모델을 훈련함."
      ],
      "metadata": {
        "id": "FpjSFbAkqmX_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(partial_x_train, partial_y_train, epochs = 20, batch_size =512, validation_data=(x_val,y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcjP8GSzqrJD",
        "outputId": "b062f00e-da54-47e9-abcf-edd8b8414de9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "16/16 [==============================] - 2s 87ms/step - loss: 2.6013 - accuracy: 0.5476 - val_loss: 1.7212 - val_accuracy: 0.6410\n",
            "Epoch 2/20\n",
            "16/16 [==============================] - 2s 100ms/step - loss: 1.4083 - accuracy: 0.7110 - val_loss: 1.2810 - val_accuracy: 0.7320\n",
            "Epoch 3/20\n",
            "16/16 [==============================] - 2s 107ms/step - loss: 1.0332 - accuracy: 0.7777 - val_loss: 1.1138 - val_accuracy: 0.7650\n",
            "Epoch 4/20\n",
            "16/16 [==============================] - 1s 88ms/step - loss: 0.8124 - accuracy: 0.8281 - val_loss: 1.0377 - val_accuracy: 0.7670\n",
            "Epoch 5/20\n",
            "16/16 [==============================] - 1s 59ms/step - loss: 0.6451 - accuracy: 0.8673 - val_loss: 0.9699 - val_accuracy: 0.7860\n",
            "Epoch 6/20\n",
            "16/16 [==============================] - 1s 77ms/step - loss: 0.5128 - accuracy: 0.8949 - val_loss: 0.9530 - val_accuracy: 0.8040\n",
            "Epoch 7/20\n",
            "16/16 [==============================] - 1s 65ms/step - loss: 0.4142 - accuracy: 0.9163 - val_loss: 0.9024 - val_accuracy: 0.8140\n",
            "Epoch 8/20\n",
            "16/16 [==============================] - 1s 93ms/step - loss: 0.3363 - accuracy: 0.9282 - val_loss: 0.8934 - val_accuracy: 0.8050\n",
            "Epoch 9/20\n",
            "16/16 [==============================] - 2s 98ms/step - loss: 0.2803 - accuracy: 0.9379 - val_loss: 0.8872 - val_accuracy: 0.8150\n",
            "Epoch 10/20\n",
            "16/16 [==============================] - 2s 127ms/step - loss: 0.2372 - accuracy: 0.9450 - val_loss: 0.9221 - val_accuracy: 0.8060\n",
            "Epoch 11/20\n",
            "16/16 [==============================] - 1s 57ms/step - loss: 0.2062 - accuracy: 0.9496 - val_loss: 0.9333 - val_accuracy: 0.8120\n",
            "Epoch 12/20\n",
            "16/16 [==============================] - 1s 58ms/step - loss: 0.1821 - accuracy: 0.9500 - val_loss: 0.9052 - val_accuracy: 0.8200\n",
            "Epoch 13/20\n",
            "16/16 [==============================] - 1s 58ms/step - loss: 0.1630 - accuracy: 0.9538 - val_loss: 0.9618 - val_accuracy: 0.8090\n",
            "Epoch 14/20\n",
            "16/16 [==============================] - 1s 58ms/step - loss: 0.1509 - accuracy: 0.9545 - val_loss: 0.9536 - val_accuracy: 0.8140\n",
            "Epoch 15/20\n",
            "16/16 [==============================] - 1s 58ms/step - loss: 0.1399 - accuracy: 0.9549 - val_loss: 0.9671 - val_accuracy: 0.8130\n",
            "Epoch 16/20\n",
            "16/16 [==============================] - 1s 58ms/step - loss: 0.1319 - accuracy: 0.9577 - val_loss: 0.9670 - val_accuracy: 0.8140\n",
            "Epoch 17/20\n",
            "16/16 [==============================] - 1s 59ms/step - loss: 0.1249 - accuracy: 0.9578 - val_loss: 1.0541 - val_accuracy: 0.8020\n",
            "Epoch 18/20\n",
            "16/16 [==============================] - 1s 57ms/step - loss: 0.1188 - accuracy: 0.9577 - val_loss: 1.0638 - val_accuracy: 0.7980\n",
            "Epoch 19/20\n",
            "16/16 [==============================] - 1s 58ms/step - loss: 0.1133 - accuracy: 0.9582 - val_loss: 1.0401 - val_accuracy: 0.8030\n",
            "Epoch 20/20\n",
            "16/16 [==============================] - 1s 56ms/step - loss: 0.1134 - accuracy: 0.9584 - val_loss: 1.0683 - val_accuracy: 0.7990\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.clf()\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(loss) + 1)\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label = 'Training loss')\n",
        "plt.plot(epochs, val_loss,'b', label = 'Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "wSonIte8q5nx",
        "outputId": "f4edb754-2a61-49e7-999f-90be3b8a006e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZgU1dn38e/NzjCIbIqyE3FDYYBBVBRR80RAXnCPhKiEuMBj3OOSkCivCe/1REkeQ9QY3BciGjUEIy5xQTDGxAERQTGoYRRFRZBNRAHv949TA83Q3dPDTHX3TP8+11VXV9fWd9f01F11zqlT5u6IiEjhapDrAEREJLeUCERECpwSgYhIgVMiEBEpcEoEIiIFTolARKTAKRFIrTKzJ83snNpeNpfMbLmZfTuG7bqZ7ReN32ZmP89k2d34nDFm9szuxplmu0PMbEVtb1eyr1GuA5DcM7ONCW+LgK+AbdH7C9x9eqbbcvdhcSxb37n7+NrYjpl1A/4DNHb3rdG2pwMZ/w2l8CgRCO5eXDFuZsuBc9392crLmVmjioOLiNQfKhqSlCou/c3sajP7GLjbzFqb2V/NbJWZfR6Nd0pYZ46ZnRuNjzWzl8xsSrTsf8xs2G4u293M5prZBjN71sxuMbMHUsSdSYy/MLO/R9t7xszaJcw/y8zKzWy1mU1Ms38GmtnHZtYwYdrJZrYoGj/MzP5hZmvNbKWZ3WxmTVJs6x4z+2XC+yujdT4ys3GVlj3RzF4zs/Vm9oGZTUqYPTd6XWtmG83siIp9m7D+kWb2qpmti16PzHTfpGNmB0XrrzWzJWY2MmHecDN7M9rmh2b242h6u+jvs9bM1pjZPDPTcSnLtMOlKh2ANkBX4HzCb+bu6H0X4Evg5jTrDwTeBtoBNwB3mpntxrJ/BP4FtAUmAWel+cxMYvwe8ANgL6AJUHFgOhj4fbT9faPP60QS7v5P4AvguErb/WM0vg24LPo+RwDHA/+dJm6iGIZG8fwX0BOoXD/xBXA2sCdwIjDBzE6K5g2OXvd092J3/0elbbcBngCmRt/tN8ATZta20nfYZd9UEXNj4HHgmWi9i4DpZnZAtMidhGLGlsAhwPPR9CuAFUB7YG/gp4D6vckyJQKpyjfAde7+lbt/6e6r3f1Rd9/k7huAycAxadYvd/fb3X0bcC+wD+EfPuNlzawLMAC41t2/dveXgFmpPjDDGO9293+7+5fAw0BJNP004K/uPtfdvwJ+Hu2DVB4ERgOYWUtgeDQNd5/v7q+4+1Z3Xw78IUkcyZwRxbfY3b8gJL7E7zfH3d9w92/cfVH0eZlsF0LiWObu90dxPQgsBf5PwjKp9k06hwPFwP9Ef6Pngb8S7RtgC3Cwme3h7p+7+4KE6fsAXd19i7vPc3WAlnVKBFKVVe6+ueKNmRWZ2R+iopP1hKKIPROLRyr5uGLE3TdFo8XVXHZfYE3CNIAPUgWcYYwfJ4xvSohp38RtRwfi1ak+i3D2f4qZNQVOARa4e3kUx/5RscfHURz/j3B1UJWdYgDKK32/gWb2QlT0tQ4Yn+F2K7ZdXmlaOdAx4X2qfVNlzO6emDQTt3sqIUmWm9mLZnZENP1G4B3gGTN7z8yuyexrSG1SIpCqVD47uwI4ABjo7nuwoygiVXFPbVgJtDGzooRpndMsX5MYVyZuO/rMtqkWdvc3CQe8YexcLAShiGkp0DOK46e7EwOheCvRHwlXRJ3dvRVwW8J2qzqb/ohQZJaoC/BhBnFVtd3Olcr3t2/X3V9191GEYqOZhCsN3H2Du1/h7j2AkcDlZnZ8DWORalIikOpqSShzXxuVN18X9wdGZ9hlwCQzaxKdTf6fNKvUJMZHgBFmdlRUsXs9Vf+f/BG4hJBw/lQpjvXARjM7EJiQYQwPA2PN7OAoEVWOvyXhCmmzmR1GSEAVVhGKsnqk2PZsYH8z+56ZNTKz7wIHE4pxauKfhKuHq8yssZkNIfyNZkR/szFm1srdtxD2yTcAZjbCzPaL6oLWEepV0hXFSQyUCKS6bgKaA58BrwBPZelzxxAqXFcDvwQeItzvkMxux+juS4ALCQf3lcDnhMrMdCrK6J93988Spv+YcJDeANwexZxJDE9G3+F5QrHJ85UW+W/gejPbAFxLdHYdrbuJUCfy96glzuGVtr0aGEG4aloNXAWMqBR3tbn714QD/zDCfr8VONvdl0aLnAUsj4rIxhP+nhAqw58FNgL/AG519xdqEotUn6leRuoiM3sIWOrusV+RiNR3uiKQOsHMBpjZt8ysQdS8chShrFlEakh3Fktd0QF4jFBxuwKY4O6v5TYkkfpBRUMiIgVORUMiIgWuzhUNtWvXzrt165brMERE6pT58+d/5u7tk82rc4mgW7dulJWV5ToMEZE6xcwq31G+nYqGREQKnBKBiEiBUyIQESlwda6OQESyb8uWLaxYsYLNmzdXvbDkVLNmzejUqRONGzfOeB0lAhGp0ooVK2jZsiXdunUj9XOFJNfcndWrV7NixQq6d++e8XoFUTQ0fTp06wYNGoTX6XqMt0i1bN68mbZt2yoJ5Dkzo23bttW+cqv3VwTTp8P558Om6JEm5eXhPcCYManXE5GdKQnUDbvzd6r3VwQTJ+5IAhU2bQrTRUSkABLB++9Xb7qI5J/Vq1dTUlJCSUkJHTp0oGPHjtvff/3112nXLSsr4+KLL67yM4488shaiXXOnDmMGDGiVraVLfU+EXSp/JC/KqaLSM3Vdr1c27ZtWbhwIQsXLmT8+PFcdtll2983adKErVu3ply3tLSUqVOnVvkZL7/8cs2CrMPqfSKYPBmKinaeVlQUpotI7auolysvB/cd9XK13Uhj7NixjB8/noEDB3LVVVfxr3/9iyOOOIK+ffty5JFH8vbbbwM7n6FPmjSJcePGMWTIEHr06LFTgiguLt6+/JAhQzjttNM48MADGTNmDBW9NM+ePZsDDzyQ/v37c/HFF1d55r9mzRpOOukkevfuzeGHH86iRYsAePHFF7df0fTt25cNGzawcuVKBg8eTElJCYcccgjz5s2r3R2WRr2vLK6oEJ44MRQHdekSkoAqikXika5errb/71asWMHLL79Mw4YNWb9+PfPmzaNRo0Y8++yz/PSnP+XRRx/dZZ2lS5fywgsvsGHDBg444AAmTJiwS5v71157jSVLlrDvvvsyaNAg/v73v1NaWsoFF1zA3Llz6d69O6NHj64yvuuuu46+ffsyc+ZMnn/+ec4++2wWLlzIlClTuOWWWxg0aBAbN26kWbNmTJs2jRNOOIGJEyeybds2NlXeiTGq94kAwo9PB36R7Mhmvdzpp59Ow4YNAVi3bh3nnHMOy5Ytw8zYsmVL0nVOPPFEmjZtStOmTdlrr7345JNP6NSp007LHHbYYdunlZSUsHz5coqLi+nRo8f29vmjR49m2rRpaeN76aWXtiej4447jtWrV7N+/XoGDRrE5ZdfzpgxYzjllFPo1KkTAwYMYNy4cWzZsoWTTjqJkpKSGu2b6oitaMjMOpvZC2b2ppktMbNLkiwzxMzWmdnCaLg2rnhEJDuyWS/XokWL7eM///nPOfbYY1m8eDGPP/54yrb0TZs23T7esGHDpPULmSxTE9dccw133HEHX375JYMGDWLp0qUMHjyYuXPn0rFjR8aOHct9991Xq5+ZTpx1BFuBK9z9YOBw4EIzOzjJcvPcvSQaro8xHhHJglzVy61bt46OHTsCcM8999T69g844ADee+89li9fDsBDDz1U5TpHH30006PKkTlz5tCuXTv22GMP3n33XQ499FCuvvpqBgwYwNKlSykvL2fvvffmvPPO49xzz2XBggW1/h1SiS0RuPtKd18QjW8A3gI6xvV5IpIfxoyBadOga1cwC6/TpsVfPHvVVVfxk5/8hL59+9b6GTxA8+bNufXWWxk6dCj9+/enZcuWtGrVKu06kyZNYv78+fTu3ZtrrrmGe++9F4CbbrqJQw45hN69e9O4cWOGDRvGnDlz6NOnD3379uWhhx7ikkt2KUSJTVaeWWxm3YC5wCHuvj5h+hDgUcLDyD8CfuzuS5Ksfz5wPkCXLl36l5enfL6CiMTgrbfe4qCDDsp1GDm3ceNGiouLcXcuvPBCevbsyWWXXZbrsHaR7O9lZvPdvTTZ8rE3HzWzYsLB/tLEJBBZAHR19z7A74CZybbh7tPcvdTdS9u3T/qkNRGR2N1+++2UlJTQq1cv1q1bxwUXXJDrkGpFrK2GzKwxIQlMd/fHKs9PTAzuPtvMbjWzdu7+WZxxiYjsjssuuywvrwBqKs5WQwbcCbzl7r9JsUyHaDnM7LAontVxxSQiIruK84pgEHAW8IaZLYym/RToAuDutwGnARPMbCvwJXCmZ6PSQkREtostEbj7S0Da/lDd/Wbg5rhiEBGRqtX7voZERCQ9JQIRyXvHHnssTz/99E7TbrrpJiZMmJBynSFDhlBWVgbA8OHDWbt27S7LTJo0iSlTpqT97JkzZ/Lmm29uf3/ttdfy7LPPVif8pPKpu2olAhHJe6NHj2bGjBk7TZsxY0ZGHb9B6DV0zz333K3PrpwIrr/+er797W/v1rbylRKBiOS90047jSeeeGL7Q2iWL1/ORx99xNFHH82ECRMoLS2lV69eXHfddUnX79atG599FlqlT548mf3335+jjjpqe1fVEO4RGDBgAH369OHUU09l06ZNvPzyy8yaNYsrr7ySkpIS3n33XcaOHcsjjzwCwHPPPUffvn059NBDGTduHF999dX2z7vuuuvo168fhx56KEuXLk37/XLdXXVB9D4qIrXn0kth4cKql6uOkhK46abU89u0acNhhx3Gk08+yahRo5gxYwZnnHEGZsbkyZNp06YN27Zt4/jjj2fRokX07t076Xbmz5/PjBkzWLhwIVu3bqVfv370798fgFNOOYXzzjsPgJ/97GfceeedXHTRRYwcOZIRI0Zw2mmn7bStzZs3M3bsWJ577jn2339/zj77bH7/+99z6aWXAtCuXTsWLFjArbfeypQpU7jjjjtSfr9cd1etKwIRqRMSi4cSi4Uefvhh+vXrR9++fVmyZMlOxTiVzZs3j5NPPpmioiL22GMPRo4cuX3e4sWLOfroozn00EOZPn06S5bs0tvNTt5++226d+/O/vvvD8A555zD3Llzt88/5ZRTAOjfv//2jupSeemllzjrrLOA5N1VT506lbVr19KoUSMGDBjA3XffzaRJk3jjjTdo2bJl2m1nQlcEIlIt6c7c4zRq1Cguu+wyFixYwKZNm+jfvz//+c9/mDJlCq+++iqtW7dm7NixKbufrsrYsWOZOXMmffr04Z577mHOnDk1ireiK+uadGN9zTXXcOKJJzJ79mwGDRrE008/vb276ieeeIKxY8dy+eWXc/bZZ9coVl0RiEidUFxczLHHHsu4ceO2Xw2sX7+eFi1a0KpVKz755BOefPLJtNsYPHgwM2fO5Msvv2TDhg08/vjj2+dt2LCBffbZhy1btmzvOhqgZcuWbNiwYZdtHXDAASxfvpx33nkHgPvvv59jjjlmt75brrur1hWBiNQZo0eP5uSTT95eRFTRbfOBBx5I586dGTRoUNr1+/Xrx3e/+1369OnDXnvtxYABA7bP+8UvfsHAgQNp3749AwcO3H7wP/PMMznvvPOYOnXq9kpigGbNmnH33Xdz+umns3XrVgYMGMD48eN363tVPEu5d+/eFBUV7dRd9QsvvECDBg3o1asXw4YNY8aMGdx44400btyY4uLiWnmATVa6oa5NpaWlXtE2WESyQ91Q1y151w21iIjkNyUCEZECp0QgIhmpa8XIhWp3/k5KBCJSpWbNmrF69Wolgzzn7qxevZpmzZpVaz21GhKRKnXq1IkVK1awatWqXIciVWjWrBmdOnWq1jpKBCJSpcaNG9O9e/dchyExUdGQiEiBUyIQESlwSgQiIgVOiUBEpMApEYiIFDglAhGRAqdEICJS4JQIREQKnBKBiEiBUyIQESlwSgQiIgVOiUBEpMApEYiIFDglAhGRAqdEICJS4GJLBGbW2cxeMLM3zWyJmV2SZBkzs6lm9o6ZLTKzfnHFIyIiycX5YJqtwBXuvsDMWgLzzexv7v5mwjLDgJ7RMBD4ffQqIiJZEtsVgbuvdPcF0fgG4C2gY6XFRgH3efAKsKeZ7RNXTCIisqus1BGYWTegL/DPSrM6Ah8kvF/BrskCMzvfzMrMrEzPTBURqV2xJwIzKwYeBS519/W7sw13n+bupe5e2r59+9oNUESkwMWaCMysMSEJTHf3x5Is8iHQOeF9p2iaiIhkSZythgy4E3jL3X+TYrFZwNlR66HDgXXuvjKumEREZFdxthoaBJwFvGFmC6NpPwW6ALj7bcBsYDjwDrAJ+EGM8YiISBKxJQJ3fwmwKpZx4MK4YhARkarpzmIRkQKnRCAiUuCUCERECpwSgYhIgVMiEBEpcEoEIiIFTolARKTAKRGIiBQ4JQIRkQKnRCAiUuCUCERECpwSgYhIgVMiEBEpcEoEIiIFTolARKTAFUwieP11OOss2Lw515GIiOSXgkkEq1fDAw/A/ffnOhIRkfxSMIng2GOhXz+YMgW++SbX0YiI5I+CSQRmcNVV8O9/w6xZuY5GRCR/FEwiADj1VOjWDW68MdeRiIjkj4JKBI0aweWXw8svh0FERAosEQCMGwdt2uiqQESkQsElghYt4MIL4S9/gbffznU0IiK5V3CJAOBHP4KmTeHXv851JCIiuVeQiWCvveCcc+C+++CTT3IdjYhIbhVkIgC44gr4+mv43e9yHYmISG4VbCLo2RNOPhluvRU2bsx1NCIiuVOwiQDgyivh88/hzjtzHYmISO4UdCI4/HA46ij43/+FrVtzHY2ISG4UdCKAcFVQXg5/+lOuIxERyY2CTwQjRsCBB4YbzNxzHY2ISPbFlgjM7C4z+9TMFqeYP8TM1pnZwmi4Nq5Y0mnQAH78Y3jtNXjuuVxEICKSW3FeEdwDDK1imXnuXhIN18cYS1rf/z506KBuJ0SkMMWWCNx9LrAmru3XpqZN4eKL4ZlnwpPMREQKSa7rCI4ws9fN7Ekz65VqITM738zKzKxs1apVsQQyfnzoh2jKlFg2LyKSt3KZCBYAXd29D/A7YGaqBd19mruXuntp+/btYwmmdWs4/3x48EF4//1YPkJEJC/lLBG4+3p33xiNzwYam1m7XMUDcOml4fWmm3IZhYhIdmWUCMyshZk1iMb3N7ORZta4Jh9sZh3MzKLxw6JYVtdkmzXVpQuceSbcfjusXZvLSEREsifTK4K5QDMz6wg8A5xFaBWUkpk9CPwDOMDMVpjZD81svJmNjxY5DVhsZq8DU4Ez3XPfkv/KK0PfQ7fdtmPa9OnhEZcNGoTX6dNzFZ2ISO2zTI69ZrbA3fuZ2UVAc3e/wcwWuntJ/CHurLS01MvKymL9jBNOgEWLYPlyeOSRUHewadOO+UVFMG0ajBkTaxgiIrXGzOa7e2myeZleEZiZHQGMAZ6IpjWsjeDy0ZVXwscfwwMPwMSJOycBCO8nTsxNbCIitS3TRHAp8BPgz+6+xMx6AC/EF1ZuHX88lJSEpqTl5cmXUcsiEakvMkoE7v6iu490919FlcafufvFMceWM2bhqmDpUkjVWrVLl+zGJCISl0xbDf3RzPYwsxbAYuBNM7sy3tBy6/TToWvXcH9BUdHO84qKYPLk3MQlIlLbMi0aOtjd1wMnAU8C3Qkth+qtxo3hssvg3/+Gq64KScEsvKqiWETqk0wTQePovoGTgFnuvgXIeVPPuP3wh+GKoKIF0TffhFclARGpTzJNBH8AlgMtgLlm1hVYH1dQ+aK4GCZMgD//GZYty3U0IiLxyLSyeKq7d3T34R6UA8fGHFteuOgiaNIEfv3rXEciIhKPTCuLW5nZbyp6ADWzXxOuDuq9Dh3g7LPhnnvg009zHY2ISO3LtGjoLmADcEY0rAfujiuofHPFFfD113DzzbmORESk9mWaCL7l7te5+3vR8H+BHnEGlk8OOABGjoRbboGYHocgIpIzmSaCL83sqIo3ZjYI+DKekPLTz38eupY47DBYnPQpzCIidVOmiWA8cIuZLTez5cDNwAWxRZWH+veHuXPhq6/giCPg8cdzHZGISO3ItNXQ69GTxHoDvd29L3BcrJHloQED4NVXQ1HRqFFwww2Q+46zRURqplpPKIueKlZx/8DlMcST9zp2DFcGZ5wBV18NY8fC5s25jkpEZPfV5FGVVmtR1DFFReHZxtdfD/fdB8cdF7qtFhGpi2qSCAq6UMQsVCA/8gi8/nqoRH7ttVxHJSJSfWkTgZltMLP1SYYNwL5ZijGvnXoqvPRSqCs46ih47LFcRyQiUj1pE4G7t3T3PZIMLd29UbaCzHd9+4ZK5EMPDYnhl79UJbKI1B01KRqSBB06wJw58P3vhyKj730PviyoOy1EpK5SIqhFzZqFyuP/+R946CEYPBg++ijXUYmIpKdEUMvMQrPSmTPhrbd23HsgIpKvlAhiMnIkvPxyeNLZ4MEwY0auIxIRSU6JIEa9e4ergdJSGD0afvaz0F+RiEg+USKIWfv28Oyz8IMfhAfe77MPnH8+/OMfalkkIvlBiSALmjaFO++EF1+EU06BP/4RjjwSDjooVCx/+GGuIxSRQqZEkCVmoa7g7rth5Uq46y7Yay/4yU+gSxcYNiy0NFK/RSKSbeZ1rHyitLTUy8rKch1GrXnnHbj33jB88AG0bh3qE8aODXULVrA9Oolk3zffwMaNOw8bNoTXL76ANm3CiVvnztC8eXxxbNsGK1bAu++GY0TFMHJkODbsDjOb7+6lSecpEcRv+nSYOBHefz/8iCZPhjFjdl5m2zZ44YVwxfDYY+HKoFevULcwZky4YU1Eds9774X/rQ8+SH6Qrxiq05ijffvw/5xq2GsvaJCmzGXLFigv3/lAX3Hgf++98HjcCk2aQI8e8N//DRddtHv7QIkgh6ZPD5XDiT+woiKYNm3XZFBh7dpQTHTPPfDKK9CwIQwfHs4Ehg8PN66JSHru4eTqt78ND5Jq0CB0I19cHIaWLXeMZ/K+RQtYvTqc0FUeystDIknUpEm4cqhIDJ06weef7zjol5eHE8AKRUWw335h+Na3dozvt1+Iu2HDmu2PnCQCM7sLGAF86u6HJJlvwG+B4cAmYKy7L6hqu3UtEXTrFv7glXXtCsuXV73+W2+FhHD//aFuoWXL8FCcM86A73wnVESLyA6bNoUTsKlTw2Nl27WD8ePD0LFjPJ/pDuvWJU8SFcOHH4b/3549kx/s99473qLgXCWCwcBG4L4UiWA4cBEhEQwEfuvuA6vabl1LBA0aJG8mahbKIzO1dSs89xw8/DD8+c/hzGKPPeCkk0JS+K//CmcgIoXqgw/gllvg9tthzRro0wcuuSTUueXDVfS2beF4kKt6v3SJILZWQ+4+F1iTZpFRhCTh7v4KsKeZ7RNXPLnSpUv1pqfSqBGccEJohvrxxzB7dmiK+pe/wIgR4Wxi3Dh46qlQ9ihSCNxDN/Cnnw7du8ONN8KQIaGp9muvhTq2fEgCEIp28rXxRy6bj3YEPkh4vyKatgszO9/MysysbNWqVVkJrrZMnhzK/hIVFYXpu6tJk9Dc9O674dNP4a9/Da0JHn00TN97bzj3XHjmGSUFqZ+++iq0tCsthaOPDjdtXn55qGx99NHQVDtfD7r5qE7cR+Du09y91N1L27dvn+twqmXMmFAx3LVr+GF27Zq+ori6mjSBE08M/xSffgqzZoX3Dz8criAq7mR+9tlQvCRSl61cCddeG66oK54XftttoanlDTeEOjmpvlhbDZlZN+CvKeoI/gDMcfcHo/dvA0PcfWW6bda1OoJc2bwZnn46JIRZs0KLhj33DP8o7duHYa+9Ur+2bKkzqvpky5bwSNVt28IVaYsW4bVivCYtUtxh/fpQb1UxrFmz8/vPPw+t4RJbySST7jf3xRfwt7+FE5oTT4SLL4Zvf1u/00ylqyPI5VPGZgE/MrMZhMridVUlAclcs2ahddGoUeEBOU89FYaVK2HVqnAJvWpVaEedTJMmuyaIDh3g8MPhmGNCSwzJb++/H04GnnoqXBGuX5962SZNdk0OlRNG8+bhYFz5IL92bfqGD40ahRsl99wz9MabSlXnpGYwYUJoR7/ffumXleqJs9XQg8AQoB3wCXAd0BjA3W+Lmo/eDAwlNB/9gbtXeaqvK4LatXlzSAifflr168qVoWwWwmM5hwwJw+DBSgz5YPNmmDdvR9J/880wvXNnGDo0nD0XF4fmlZs2hYN64muq8cRpLVqEu2tbt04+JJvXooXO2vOBbiiTWrFlC5SVhUdyzpkTWmtU3CiXmBiOOQbats1dnHFwDzcTrVkTzqzXrQuvFUNV79evDwfUffbZue14RVvyHj12bVSQSUzLlu048M+ZE67+mjQJf4OhQ8Nw0EE6EIsSgcTk6693Tgx///uOxNC7985XDHUpMaxbB0uWhJuR3ngjvC5eDJ99ln69Zs3CvR2JQ6tWO8abNw83FVV0I7CmUuPqjh13vcmo4v0ee4RlNmwId8tWHPz/858wvWfPHQf+Y44JZ+EiiZQIJCsqJ4aXXgpnqBASw9FHh/qGitv1K79WnlZUFO+Z7ObNsHTpzgf7xYtD2XqF4mI45JAw9OoV6koqH+Arhure0LdmTUgKlTsWe/fdcK9IovbtYd99Q3HPli1hHx1/fDjwn3BCuKIQSUeJQHLi66/DE9oqEsMrr+zaH0tVKieI5s1DtxrNmiUfUs1r2jTc1bls2Y4z/WXLdlRyNm4cilAOOSQUc1Uc/Lt0Sd9xWFw2btyRICpe338/3C07dGh4noW6F5HqUCKQvLF1aygr/+KLHV37Zvr6xRfhLD5x+OqrXadt3py6BYpZKG5JPNgfckgoWknXokWkrsvX5qNSgBo1CsUqrVrF9xnuIeFUThhbtoQb+qpbKStS3ykRSL1jFs7uGzcON8aJSHp1oouJQjd9ergjuEGD8Dp9eq4jEpH6RFcEea7yg23Ky8N7qL3+ikSksOmKIM9NnLjr4/M2bQrTRURqgxJBnvCv7KsAAAtZSURBVEts057JdBGR6lIiyHO19WAbEZFUlAjyXBwPthERSaREkOfifrCNiIhaDdUBY8bowC8i8dEVgYhIgVMiEBEpcEoEIiIFTolARKTAKRGIiBQ4JQIRkQKnRFAA1HupiKSj+wjqOfVeKiJV0RVBPafeS0WkKkoE9Zx6LxWRqigR1HPqvVREqqJEUM+p91IRqYoSQT2n3ktFpCpqNVQA1HupiKSjKwIRkQKnRCAiUuCUCCQjujtZpP6KNRGY2VAze9vM3jGza5LMH2tmq8xsYTScG2c8snsq7k4uLwf3HXcnKxmI1A+xJQIzawjcAgwDDgZGm9nBSRZ9yN1LouGOuOKR3ae7k0XqtzivCA4D3nH399z9a2AGMCrGz5OY6O5kkfotzkTQEfgg4f2KaFplp5rZIjN7xMw6J9uQmZ1vZmVmVrZq1ao4YpU0dHeySP2W68rix4Fu7t4b+Btwb7KF3H2au5e6e2n79u2zGqDo7mSR+i7ORPAhkHiG3ymatp27r3b3r6K3dwD9Y4xHdpPuThap3+K8s/hVoKeZdSckgDOB7yUuYGb7uPvK6O1I4K0Y45Ea0N3JIvVXbFcE7r4V+BHwNOEA/7C7LzGz681sZLTYxWa2xMxeBy4GxsYVj+SW7kMQyV/m7rmOoVpKS0u9rKws12FINVR+ShqEOgYVL4lkj5nNd/fSZPNyXVksBUD3IYjkNyUCiZ3uQxDJb0oEEjvdhyCS35QIJHa6D0EkvykRSOxq4z4EtToSiY+eUCZZUZP7ECq3Oqro/bRiuyJSM7oikLynVkci8VIikLynVkci8VIikLynVkci8VIikLxXG62OVNkskpoSgeS9mrY60qM2RdJTX0NS73XrFg7+lXXtCsuXZzsakdxQX0NS0GqjsllFS1KfKRFIvVfTymYVLUl9p0Qg9V5NK5t1H4PUd0oEUu/VtLJZRUtS3ykRSEEYMyZUDH/zTXitTtcU+VC0pEQicVIiEKlCrouWVEchcVMiEKlCrouWaqOOQlcUko4SgUgGclm0VNNEoqIpqYoSgUjMalq0VNNEkg9FUzVNJEpEMXP3OjX079/fReqaBx5w79rV3Sy8PvBA9dYtKnIPh+EwFBVlvg2zndetGMwyW79r1+Trd+2anfhrun7FNnZ3/9fG+vkAKPMUx9WcH9irOygRSCGqyYGopgfyXCcSJaLaSURKBCIFrKYHslwnEiWimici9/SJQHUEIvVcTVs95bqOI9eV7blu9ZWNO9uVCEQKQE1aPeU6kSgR1Wz9TCgRiEiVcplIlIhqtn5GUpUZ5eugOgIRqa5cVtbWhToCPZhGRCRm06eHMv333w9n8pMnV++qqqbrQ/oH0ygRiIgUAD2hTEREUoo1EZjZUDN728zeMbNrksxvamYPRfP/aWbd4oxHRER2FVsiMLOGwC3AMOBgYLSZHVxpsR8Cn7v7fsD/Ar+KKx4REUkuziuCw4B33P09d/8amAGMqrTMKODeaPwR4HgzsxhjEhGRSuJMBB2BDxLer4imJV3G3bcC64C2lTdkZuebWZmZla1atSqmcEVEClOjXAeQCXefBkwDMLNVZlae45BSaQd8lusg0sj3+CD/Y1R8NaP4aqYm8XVNNSPORPAh0DnhfadoWrJlVphZI6AVsDrdRt29fW0GWZvMrCxV86x8kO/xQf7HqPhqRvHVTFzxxVk09CrQ08y6m1kT4ExgVqVlZgHnROOnAc97XbuxQUSkjovtisDdt5rZj4CngYbAXe6+xMyuJ9zqPAu4E7jfzN4B1hCShYiIZFGsdQTuPhuYXWnatQnjm4HT44why6blOoAq5Ht8kP8xKr6aUXw1E0t8da6LCRERqV3qYkJEpMApEYiIFDglgmoys85m9oKZvWlmS8zskiTLDDGzdWa2MBquTbatGGNcbmZvRJ+9S1etFkyN+nhaZGb9shjbAQn7ZaGZrTezSystk/X9Z2Z3mdmnZrY4YVobM/ubmS2LXlunWPecaJllZnZOsmViiu9GM1sa/Q3/bGZ7plg37e8hxvgmmdmHCX/H4SnWTdsnWYzxPZQQ23IzW5hi3Vj3X6pjSlZ/f6keVKAh+QDsA/SLxlsC/wYOrrTMEOCvOYxxOdAuzfzhwJOAAYcD/8xRnA2Bj4Guud5/wGCgH7A4YdoNwDXR+DXAr5Ks1wZ4L3ptHY23zlJ83wEaReO/ShZfJr+HGOObBPw4g9/Au0APoAnweuX/p7jiqzT/18C1udh/qY4p2fz96Yqgmtx9pbsviMY3AG+xa9cZ+W4UcJ8HrwB7mtk+OYjjeOBdd8/5neLuPpfQhDlRYl9Y9wInJVn1BOBv7r7G3T8H/gYMzUZ87v6Mh65ZAF4h3LSZEyn2XyYy6ZOsxtLFF/VvdgbwYG1/bibSHFOy9vtTIqiBqNvsvsA/k8w+wsxeN7MnzaxXVgMDB54xs/lmdn6S+Zn0A5UNZ5L6ny+X+6/C3u6+Mhr/GNg7yTL5si/HEa7ykqnq9xCnH0VFV3elKNrIh/13NPCJuy9LMT9r+6/SMSVrvz8lgt1kZsXAo8Cl7r6+0uwFhOKOPsDvgJlZDu8od+9H6AL8QjMbnOXPr1J0t/lI4E9JZud6/+3Cw3V4Xra1NrOJwFZgeopFcvV7+D3wLaAEWEkofslHo0l/NZCV/ZfumBL370+JYDeYWWPCH2y6uz9Web67r3f3jdH4bKCxmbXLVnzu/mH0+inwZ8Lld6JM+oGK2zBggbt/UnlGrvdfgk8qisyi10+TLJPTfWlmY4ERwJjoYLGLDH4PsXD3T9x9m7t/A9ye4nNzvf8aAacAD6VaJhv7L8UxJWu/PyWCaorKE+8E3nL336RYpkO0HGZ2GGE/p+1Mrxbja2FmLSvGCRWKiystNgs4O2o9dDiwLuESNFtSnoXlcv9VktgX1jnAX5Is8zTwHTNrHRV9fCeaFjszGwpcBYx0900plsnk9xBXfIn1Tien+NxM+iSL07eBpe6+ItnMbOy/NMeU7P3+4qoJr68DcBThEm0RsDAahgPjgfHRMj8ClhBaQLwCHJnF+HpEn/t6FMPEaHpifEZ4ety7wBtAaZb3YQvCgb1VwrSc7j9CUloJbCGUs/6Q8GyM54BlwLNAm2jZUuCOhHXHAe9Eww+yGN87hPLhit/hbdGy+wKz0/0eshTf/dHvaxHhoLZP5fii98MJLWXezWZ80fR7Kn53Cctmdf+lOaZk7fenLiZERAqcioZERAqcEoGISIFTIhARKXBKBCIiBU6JQESkwCkRiETMbJvt3DNqrfWEaWbdEnu+FMknsT6qUqSO+dLdS3IdhEi26YpApApRf/Q3RH3S/8vM9oumdzOz56NO1Z4zsy7R9L0tPB/g9Wg4MtpUQzO7Pepz/hkzax4tf3HUF/0iM5uRo68pBUyJQGSH5pWKhr6bMG+dux8K3AzcFE37HXCvu/cmdPg2NZo+FXjRQ6d5/Qh3pAL0BG5x917AWuDUaPo1QN9oO+Pj+nIiqejOYpGImW109+Ik05cDx7n7e1HnYB+7e1sz+4zQbcKWaPpKd29nZquATu7+VcI2uhH6je8Zvb8aaOzuvzSzp4CNhF5WZ3rU4Z5ItuiKQCQznmK8Or5KGN/Gjjq6Ewl9P/UDXo16xBTJGiUCkcx8N+H1H9H4y4TeMgHGAPOi8eeACQBm1tDMWqXaqJk1ADq7+wvA1UArYJerEpE46cxDZIfmtvMDzJ9y94ompK3NbBHhrH50NO0i4G4zuxJYBfwgmn4JMM3Mfkg4859A6PkymYbAA1GyMGCqu6+ttW8kkgHVEYhUIaojKHX3z3Idi0gcVDQkIlLgdEUgIlLgdEUgIlLglAhERAqcEoGISIFTIhARKXBKBCIiBe7/AwjL0fpLDqKpAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.clf()\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label = 'Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label = 'Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "yuv74TJDrmcp",
        "outputId": "ff74a3d9-eae5-4a1d-c39d-6c1ba09ca6f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['accuracy']"
      ],
      "metadata": {
        "id": "KbBZVW_-s_Yq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 모델은 아홉 번째 에포크 이후에 과대적합이 시작됨.\n",
        "- 아홉 번의 에포크로 새로운 모델을 훈련하고 테스트 세트에서 평가 진행."
      ],
      "metadata": {
        "id": "yPKHHmghuGvx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(46, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "model.fit(partial_x_train,partial_y_train,epochs=9, batch_size = 512, validation_data = (x_val, y_val))\n",
        "results = model.evaluate(x_test, one_hot_test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGyHjHYLvJB2",
        "outputId": "80457e61-ebf0-4ba0-b102-085d417e5a05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/9\n",
            "16/16 [==============================] - 2s 70ms/step - loss: 2.6433 - accuracy: 0.5437 - val_loss: 1.7253 - val_accuracy: 0.6480\n",
            "Epoch 2/9\n",
            "16/16 [==============================] - 1s 55ms/step - loss: 1.3906 - accuracy: 0.7150 - val_loss: 1.2757 - val_accuracy: 0.7350\n",
            "Epoch 3/9\n",
            "16/16 [==============================] - 1s 54ms/step - loss: 1.0194 - accuracy: 0.7843 - val_loss: 1.1095 - val_accuracy: 0.7560\n",
            "Epoch 4/9\n",
            "16/16 [==============================] - 1s 54ms/step - loss: 0.7980 - accuracy: 0.8321 - val_loss: 1.0030 - val_accuracy: 0.7830\n",
            "Epoch 5/9\n",
            "16/16 [==============================] - 1s 52ms/step - loss: 0.6320 - accuracy: 0.8697 - val_loss: 0.9357 - val_accuracy: 0.8080\n",
            "Epoch 6/9\n",
            "16/16 [==============================] - 1s 54ms/step - loss: 0.5022 - accuracy: 0.8953 - val_loss: 0.8922 - val_accuracy: 0.8160\n",
            "Epoch 7/9\n",
            "16/16 [==============================] - 1s 54ms/step - loss: 0.4059 - accuracy: 0.9143 - val_loss: 0.8853 - val_accuracy: 0.8110\n",
            "Epoch 8/9\n",
            "16/16 [==============================] - 1s 53ms/step - loss: 0.3306 - accuracy: 0.9292 - val_loss: 0.8999 - val_accuracy: 0.8020\n",
            "Epoch 9/9\n",
            "16/16 [==============================] - 1s 53ms/step - loss: 0.2776 - accuracy: 0.9390 - val_loss: 0.8682 - val_accuracy: 0.8170\n",
            "71/71 [==============================] - 0s 4ms/step - loss: 0.9978 - accuracy: 0.7845\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKiDFDFiv6Oh",
        "outputId": "f7360c50-7689-4d8d-b011-8711ea4b39ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.997810423374176, 0.7845057845115662]"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 대략 78%의 정확도 달성!\n",
        "- 무작위로 분류했을 때 18% 정도의 정확도를 갖음. 18% << 78%"
      ],
      "metadata": {
        "id": "QXegQptWwLYk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "test_labels_copy = copy.copy(test_labels)\n",
        "np.random.shuffle(test_labels_copy)\n",
        "hits_array = np.array(test_labels) == np.array(test_labels_copy)\n",
        "float(np.sum(hits_array))/len(test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g65W_fP7wjRC",
        "outputId": "6dba560a-39d7-4f5d-c4e2-247ef0e4fca3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.17853962600178094"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 새로운 데이터에 대해 예측\n",
        "- 모델 객체의 predict 메서드는 46개의 토픽에대한 확률 분포를 반환\n",
        "- 테스트 데이터 전체에 대한 토픽을 예측"
      ],
      "metadata": {
        "id": "B55QDEWWw5qV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(x_test)"
      ],
      "metadata": {
        "id": "0ouUhbYcxdUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "precdictions의 각 항목은 길이가 46인 벡터"
      ],
      "metadata": {
        "id": "ZbsbvazSxkIe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RwCmhQex0JH",
        "outputId": "bf68961d-bddf-4b98-e630-52ad7077b29f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(46,)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이 벡터의 원소 합은 1"
      ],
      "metadata": {
        "id": "wvFTjoM6x20b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.sum(predictions[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRSYtchgx7mv",
        "outputId": "e7477721-c53f-4529-d09c-e930a329830f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0000001"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "가장 큰 값이 예측 클래스가 됨. 즉, 가장 확률이 높은 클래스"
      ],
      "metadata": {
        "id": "yhKYBHHKx9yQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.argmax(predictions[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqc4NuiJyKv0",
        "outputId": "42dee656-7b34-4bad-f217-bb33204b6831"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 레이블과 손실을 다루는 방법\n",
        "**레이블을 인코딩하는 다른 방법** : 다음과 같이 정수 텐서로 변환"
      ],
      "metadata": {
        "id": "VKErt46HyPFl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = np.array(train_labels)\n",
        "y_test = np.array(test_labels)"
      ],
      "metadata": {
        "id": "0zCesphsyv_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 이 방식을 사용하려면 손실 함수 하나만 바꾸면 됨.\n",
        "- categorical_crossentropy : 레이블이 범주형으로 인코딩 되어 있을 때 사용.  \n",
        "(범주형 데이터는 'A', 'B', 'C'와 같이 종류를 표시하는 데이터를 말한다. 카테고리(category( 데이터라고도 부른다.)\n",
        "- sparse_categorical_crossentropy : 레이블이 정수형으로 인코딩 되어 있을 때 사용."
      ],
      "metadata": {
        "id": "8cJni2pGy3oV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='rmsprop',loss='sparse_catergorical_crossentropy',metrics=['acc'])"
      ],
      "metadata": {
        "id": "vbOla3i70tNX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이 손실 함수는 인터페이스만 다를 뿐 수학적으로 catergorical_crossentropy와 동일"
      ],
      "metadata": {
        "id": "EmHhjyBm03-3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 충분히 큰 중간층을 두어야 하는 이유\n",
        "- 병목 현상 확인"
      ],
      "metadata": {
        "id": "qoNagbaR0_RU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
        "model.add(layers.Dense(4, activation='relu'))\n",
        "model.add(layers.Dense(46, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "model.fit(partial_x_train,partial_y_train,epochs=20, batch_size = 128, validation_data = (x_val, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ypu3cgu1LeC",
        "outputId": "37bb31b3-5bae-4629-fa23-abd7369fce8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 23ms/step - loss: 3.1373 - accuracy: 0.0712 - val_loss: 2.4442 - val_accuracy: 0.2820\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 19ms/step - loss: 1.9928 - accuracy: 0.5763 - val_loss: 1.7402 - val_accuracy: 0.5880\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 19ms/step - loss: 1.5179 - accuracy: 0.6257 - val_loss: 1.5369 - val_accuracy: 0.6260\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 19ms/step - loss: 1.3324 - accuracy: 0.6508 - val_loss: 1.4687 - val_accuracy: 0.6310\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 19ms/step - loss: 1.2188 - accuracy: 0.6637 - val_loss: 1.4469 - val_accuracy: 0.6570\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 19ms/step - loss: 1.1272 - accuracy: 0.7181 - val_loss: 1.4142 - val_accuracy: 0.6760\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 19ms/step - loss: 1.0490 - accuracy: 0.7326 - val_loss: 1.4476 - val_accuracy: 0.6860\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 19ms/step - loss: 0.9893 - accuracy: 0.7390 - val_loss: 1.4362 - val_accuracy: 0.6870\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 19ms/step - loss: 0.9338 - accuracy: 0.7471 - val_loss: 1.4341 - val_accuracy: 0.6860\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 19ms/step - loss: 0.8887 - accuracy: 0.7503 - val_loss: 1.4985 - val_accuracy: 0.6810\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 19ms/step - loss: 0.8484 - accuracy: 0.7566 - val_loss: 1.5135 - val_accuracy: 0.6900\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 19ms/step - loss: 0.8136 - accuracy: 0.7676 - val_loss: 1.5430 - val_accuracy: 0.6840\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 19ms/step - loss: 0.7817 - accuracy: 0.7732 - val_loss: 1.5582 - val_accuracy: 0.6940\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 19ms/step - loss: 0.7580 - accuracy: 0.7775 - val_loss: 1.6152 - val_accuracy: 0.6830\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 2s 31ms/step - loss: 0.7336 - accuracy: 0.7813 - val_loss: 1.6732 - val_accuracy: 0.6800\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 23ms/step - loss: 0.7118 - accuracy: 0.7821 - val_loss: 1.7100 - val_accuracy: 0.6740\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 19ms/step - loss: 0.6916 - accuracy: 0.7884 - val_loss: 1.7653 - val_accuracy: 0.6750\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 19ms/step - loss: 0.6734 - accuracy: 0.8006 - val_loss: 1.7941 - val_accuracy: 0.6730\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 19ms/step - loss: 0.6540 - accuracy: 0.8125 - val_loss: 1.8397 - val_accuracy: 0.6820\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 19ms/step - loss: 0.6409 - accuracy: 0.8137 - val_loss: 1.9031 - val_accuracy: 0.6750\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f520b51aa10>"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- validation 정확도 값의 최고값이 68%로 11% 감소했음.\n",
        "- 정확도 하락 원인 : 많은 정보를 중간층의 저차원 표현 공간으로 압축하려고 했기 때문.\n",
        "- 이 네트워크는 필요한 정보 대부분을 4차원 표현 안에 구겨 넣었지만 전부 넣지는 못했음."
      ],
      "metadata": {
        "id": "Up3MOr5f1daT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 추가 실험\n",
        "- 128개의 유닛을 사용해 더 큰 층을 구성해서 테스트"
      ],
      "metadata": {
        "id": "BAIMbUq72Mr4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dense(46, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "model.fit(partial_x_train,partial_y_train,epochs=20, batch_size = 128, validation_data = (x_val, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L22Lm_-D2m33",
        "outputId": "cf55575c-7391-4e18-8258-7b78b10d6d82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 22ms/step - loss: 1.7585 - accuracy: 0.6294 - val_loss: 1.1816 - val_accuracy: 0.7350\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 19ms/step - loss: 0.9267 - accuracy: 0.7984 - val_loss: 0.9710 - val_accuracy: 0.8010\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 19ms/step - loss: 0.6087 - accuracy: 0.8691 - val_loss: 0.8942 - val_accuracy: 0.8120\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 19ms/step - loss: 0.4136 - accuracy: 0.9117 - val_loss: 0.9153 - val_accuracy: 0.8000\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 19ms/step - loss: 0.2980 - accuracy: 0.9357 - val_loss: 0.8745 - val_accuracy: 0.8270\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 19ms/step - loss: 0.2343 - accuracy: 0.9450 - val_loss: 0.9299 - val_accuracy: 0.8100\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 19ms/step - loss: 0.1953 - accuracy: 0.9486 - val_loss: 0.9476 - val_accuracy: 0.8150\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 19ms/step - loss: 0.1733 - accuracy: 0.9538 - val_loss: 0.9935 - val_accuracy: 0.8150\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 19ms/step - loss: 0.1569 - accuracy: 0.9539 - val_loss: 1.0439 - val_accuracy: 0.7970\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 19ms/step - loss: 0.1471 - accuracy: 0.9540 - val_loss: 1.0759 - val_accuracy: 0.7890\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 19ms/step - loss: 0.1373 - accuracy: 0.9555 - val_loss: 1.0287 - val_accuracy: 0.8080\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 19ms/step - loss: 0.1326 - accuracy: 0.9560 - val_loss: 1.1107 - val_accuracy: 0.8030\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 19ms/step - loss: 0.1246 - accuracy: 0.9554 - val_loss: 1.1696 - val_accuracy: 0.7790\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 19ms/step - loss: 0.1222 - accuracy: 0.9565 - val_loss: 1.1532 - val_accuracy: 0.7910\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 19ms/step - loss: 0.1204 - accuracy: 0.9555 - val_loss: 1.1535 - val_accuracy: 0.7970\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 20ms/step - loss: 0.1154 - accuracy: 0.9572 - val_loss: 1.1233 - val_accuracy: 0.8010\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 19ms/step - loss: 0.1105 - accuracy: 0.9570 - val_loss: 1.1718 - val_accuracy: 0.8010\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 19ms/step - loss: 0.1048 - accuracy: 0.9562 - val_loss: 1.1490 - val_accuracy: 0.8050\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 19ms/step - loss: 0.1044 - accuracy: 0.9565 - val_loss: 1.2056 - val_accuracy: 0.7930\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 19ms/step - loss: 0.1013 - accuracy: 0.9553 - val_loss: 1.2138 - val_accuracy: 0.7990\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5200138d90>"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "validation 데이터 최대 정확도 : 82%로 처음 분석 보다 1% 상승"
      ],
      "metadata": {
        "id": "Ca-VCx9J2o5z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 256개의 유닛을 사용한 layer로 테스트"
      ],
      "metadata": {
        "id": "0PUSLb_H3K_d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "model.add(layers.Dense(46, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "model.fit(partial_x_train,partial_y_train,epochs=20, batch_size = 128, validation_data = (x_val, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJeumU3n3YXB",
        "outputId": "25af1096-1285-4a7e-f5d5-dabc779d70df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 23ms/step - loss: 1.6600 - accuracy: 0.6460 - val_loss: 1.1660 - val_accuracy: 0.7430\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 21ms/step - loss: 0.8740 - accuracy: 0.8042 - val_loss: 0.9606 - val_accuracy: 0.7940\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 20ms/step - loss: 0.5582 - accuracy: 0.8763 - val_loss: 0.9199 - val_accuracy: 0.7940\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 20ms/step - loss: 0.3709 - accuracy: 0.9173 - val_loss: 0.9277 - val_accuracy: 0.8170\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 20ms/step - loss: 0.2648 - accuracy: 0.9381 - val_loss: 0.9041 - val_accuracy: 0.8210\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 20ms/step - loss: 0.2141 - accuracy: 0.9466 - val_loss: 0.9657 - val_accuracy: 0.8090\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 20ms/step - loss: 0.1745 - accuracy: 0.9526 - val_loss: 0.9722 - val_accuracy: 0.8140\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 20ms/step - loss: 0.1580 - accuracy: 0.9541 - val_loss: 1.1044 - val_accuracy: 0.8080\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 20ms/step - loss: 0.1498 - accuracy: 0.9535 - val_loss: 1.0031 - val_accuracy: 0.8070\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 20ms/step - loss: 0.1437 - accuracy: 0.9529 - val_loss: 1.0857 - val_accuracy: 0.7950\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 20ms/step - loss: 0.1288 - accuracy: 0.9557 - val_loss: 1.0292 - val_accuracy: 0.8040\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 20ms/step - loss: 0.1221 - accuracy: 0.9555 - val_loss: 1.0991 - val_accuracy: 0.8040\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 20ms/step - loss: 0.1164 - accuracy: 0.9553 - val_loss: 1.2595 - val_accuracy: 0.7920\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 20ms/step - loss: 0.1098 - accuracy: 0.9580 - val_loss: 1.1731 - val_accuracy: 0.8070\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 20ms/step - loss: 0.1054 - accuracy: 0.9558 - val_loss: 1.2110 - val_accuracy: 0.8020\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 20ms/step - loss: 0.1010 - accuracy: 0.9570 - val_loss: 1.2252 - val_accuracy: 0.8090\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 20ms/step - loss: 0.0969 - accuracy: 0.9574 - val_loss: 1.3138 - val_accuracy: 0.7820\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 20ms/step - loss: 0.0922 - accuracy: 0.9570 - val_loss: 1.3456 - val_accuracy: 0.7990\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 20ms/step - loss: 0.0891 - accuracy: 0.9580 - val_loss: 1.5099 - val_accuracy: 0.7960\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 21ms/step - loss: 0.0858 - accuracy: 0.9582 - val_loss: 1.4686 - val_accuracy: 0.7980\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5201777090>"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "validation 데이터 정확도 :  82%로 1% 처음 테스트 보다 상승"
      ],
      "metadata": {
        "id": "6f9RlK113Ys3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 3개의 은닉층을 사용해 테스트"
      ],
      "metadata": {
        "id": "3TLHEJra3_Ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(46, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "model.fit(partial_x_train,partial_y_train,epochs=20, batch_size = 128, validation_data = (x_val, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wv8YUmuT4Etx",
        "outputId": "c2dbe217-72dd-44e1-dfc0-0903854ca0ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 23ms/step - loss: 1.8061 - accuracy: 0.6101 - val_loss: 1.2298 - val_accuracy: 0.7100\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 20ms/step - loss: 0.9845 - accuracy: 0.7766 - val_loss: 1.0775 - val_accuracy: 0.7510\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 2s 25ms/step - loss: 0.6754 - accuracy: 0.8414 - val_loss: 1.0618 - val_accuracy: 0.7510\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 2s 25ms/step - loss: 0.4699 - accuracy: 0.8933 - val_loss: 0.9423 - val_accuracy: 0.8100\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 20ms/step - loss: 0.3428 - accuracy: 0.9257 - val_loss: 0.9710 - val_accuracy: 0.8120\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 19ms/step - loss: 0.2614 - accuracy: 0.9414 - val_loss: 0.9719 - val_accuracy: 0.8160\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 20ms/step - loss: 0.2203 - accuracy: 0.9476 - val_loss: 1.0504 - val_accuracy: 0.8020\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 19ms/step - loss: 0.1894 - accuracy: 0.9501 - val_loss: 1.2145 - val_accuracy: 0.7820\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 19ms/step - loss: 0.1727 - accuracy: 0.9526 - val_loss: 1.0954 - val_accuracy: 0.7980\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 19ms/step - loss: 0.1617 - accuracy: 0.9525 - val_loss: 1.1475 - val_accuracy: 0.7990\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 20ms/step - loss: 0.1451 - accuracy: 0.9553 - val_loss: 1.3950 - val_accuracy: 0.7740\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 20ms/step - loss: 0.1400 - accuracy: 0.9545 - val_loss: 1.3247 - val_accuracy: 0.7730\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 20ms/step - loss: 0.1307 - accuracy: 0.9575 - val_loss: 1.2137 - val_accuracy: 0.7990\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 20ms/step - loss: 0.1258 - accuracy: 0.9567 - val_loss: 1.2989 - val_accuracy: 0.7890\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 20ms/step - loss: 0.1188 - accuracy: 0.9574 - val_loss: 1.2286 - val_accuracy: 0.7850\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 20ms/step - loss: 0.1157 - accuracy: 0.9560 - val_loss: 1.2428 - val_accuracy: 0.8000\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 20ms/step - loss: 0.1107 - accuracy: 0.9582 - val_loss: 1.4915 - val_accuracy: 0.7880\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 19ms/step - loss: 0.1080 - accuracy: 0.9560 - val_loss: 1.4776 - val_accuracy: 0.7720\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 20ms/step - loss: 0.1025 - accuracy: 0.9574 - val_loss: 1.5471 - val_accuracy: 0.7770\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 20ms/step - loss: 0.1027 - accuracy: 0.9562 - val_loss: 1.4410 - val_accuracy: 0.7980\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f52001db2d0>"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "validation 데이터 정확도 : 81%으로 처음 테스트와 비슷"
      ],
      "metadata": {
        "id": "7y5TKtRD4PPa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 4개의 은닉층을 사용해서 테스트 진행"
      ],
      "metadata": {
        "id": "1NOIy59a4dxy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(46, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "model.fit(partial_x_train,partial_y_train,epochs=20, batch_size = 128, validation_data = (x_val, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmrdRYT24knk",
        "outputId": "51f5aa94-f363-4bd8-d85f-04698a7f9233"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 3s 24ms/step - loss: 1.8427 - accuracy: 0.5955 - val_loss: 1.3134 - val_accuracy: 0.6970\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 2s 26ms/step - loss: 1.0449 - accuracy: 0.7593 - val_loss: 1.1220 - val_accuracy: 0.7500\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 2s 25ms/step - loss: 0.7272 - accuracy: 0.8371 - val_loss: 1.0458 - val_accuracy: 0.7890\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 20ms/step - loss: 0.5174 - accuracy: 0.8821 - val_loss: 1.2079 - val_accuracy: 0.7540\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 20ms/step - loss: 0.3776 - accuracy: 0.9121 - val_loss: 0.9992 - val_accuracy: 0.7990\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 20ms/step - loss: 0.2819 - accuracy: 0.9321 - val_loss: 1.4433 - val_accuracy: 0.7580\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 2s 27ms/step - loss: 0.2326 - accuracy: 0.9455 - val_loss: 1.1233 - val_accuracy: 0.7990\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 2s 29ms/step - loss: 0.1912 - accuracy: 0.9509 - val_loss: 1.2157 - val_accuracy: 0.7880\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 20ms/step - loss: 0.1760 - accuracy: 0.9520 - val_loss: 1.2397 - val_accuracy: 0.8040\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 20ms/step - loss: 0.1578 - accuracy: 0.9530 - val_loss: 1.3649 - val_accuracy: 0.7860\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 20ms/step - loss: 0.1433 - accuracy: 0.9551 - val_loss: 1.4353 - val_accuracy: 0.7810\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 20ms/step - loss: 0.1315 - accuracy: 0.9563 - val_loss: 1.3476 - val_accuracy: 0.7880\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 19ms/step - loss: 0.1240 - accuracy: 0.9562 - val_loss: 1.6241 - val_accuracy: 0.7540\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 19ms/step - loss: 0.1185 - accuracy: 0.9560 - val_loss: 1.4361 - val_accuracy: 0.7940\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 19ms/step - loss: 0.1129 - accuracy: 0.9562 - val_loss: 1.5827 - val_accuracy: 0.7840\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 20ms/step - loss: 0.1082 - accuracy: 0.9574 - val_loss: 1.6930 - val_accuracy: 0.7630\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 20ms/step - loss: 0.1066 - accuracy: 0.9575 - val_loss: 1.7483 - val_accuracy: 0.7840\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 20ms/step - loss: 0.0987 - accuracy: 0.9572 - val_loss: 1.7932 - val_accuracy: 0.7660\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 20ms/step - loss: 0.0966 - accuracy: 0.9569 - val_loss: 1.7198 - val_accuracy: 0.7740\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 20ms/step - loss: 0.0939 - accuracy: 0.9560 - val_loss: 2.0410 - val_accuracy: 0.7800\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5200558bd0>"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "validation 데이터 정확도 : 80%로 층이 깊어졌음에도 정확도 1% 하락"
      ],
      "metadata": {
        "id": "R7rAYP1F4oQ9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 은닉층 1개로 테스트"
      ],
      "metadata": {
        "id": "qNuHOm5946v_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
        "model.add(layers.Dense(46, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "model.fit(partial_x_train,partial_y_train,epochs=20, batch_size = 128, validation_data = (x_val, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XaJ8RkP49ks",
        "outputId": "c7f86d68-3e52-4682-e4c2-eb10bc14fbca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 22ms/step - loss: 1.8914 - accuracy: 0.6386 - val_loss: 1.2357 - val_accuracy: 0.7300\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 19ms/step - loss: 0.9469 - accuracy: 0.7988 - val_loss: 0.9800 - val_accuracy: 0.7910\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 18ms/step - loss: 0.6442 - accuracy: 0.8688 - val_loss: 0.8729 - val_accuracy: 0.8170\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 19ms/step - loss: 0.4598 - accuracy: 0.9073 - val_loss: 0.8193 - val_accuracy: 0.8220\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 18ms/step - loss: 0.3404 - accuracy: 0.9291 - val_loss: 0.7817 - val_accuracy: 0.8390\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 18ms/step - loss: 0.2652 - accuracy: 0.9400 - val_loss: 0.8045 - val_accuracy: 0.8320\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 18ms/step - loss: 0.2133 - accuracy: 0.9466 - val_loss: 0.8310 - val_accuracy: 0.8290\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 18ms/step - loss: 0.1846 - accuracy: 0.9516 - val_loss: 0.8481 - val_accuracy: 0.8260\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 18ms/step - loss: 0.1629 - accuracy: 0.9523 - val_loss: 0.8792 - val_accuracy: 0.8140\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 18ms/step - loss: 0.1478 - accuracy: 0.9536 - val_loss: 0.9047 - val_accuracy: 0.8200\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 18ms/step - loss: 0.1353 - accuracy: 0.9570 - val_loss: 0.9646 - val_accuracy: 0.8180\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 18ms/step - loss: 0.1268 - accuracy: 0.9568 - val_loss: 0.9753 - val_accuracy: 0.8160\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 18ms/step - loss: 0.1206 - accuracy: 0.9585 - val_loss: 0.9935 - val_accuracy: 0.8170\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 19ms/step - loss: 0.1194 - accuracy: 0.9558 - val_loss: 1.0384 - val_accuracy: 0.8150\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 18ms/step - loss: 0.1107 - accuracy: 0.9558 - val_loss: 1.0496 - val_accuracy: 0.8090\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 19ms/step - loss: 0.1106 - accuracy: 0.9559 - val_loss: 1.0621 - val_accuracy: 0.8110\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 19ms/step - loss: 0.1071 - accuracy: 0.9575 - val_loss: 1.0889 - val_accuracy: 0.8070\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 19ms/step - loss: 0.1046 - accuracy: 0.9569 - val_loss: 1.1673 - val_accuracy: 0.7990\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 18ms/step - loss: 0.1050 - accuracy: 0.9567 - val_loss: 1.1289 - val_accuracy: 0.8090\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 19ms/step - loss: 0.1014 - accuracy: 0.9602 - val_loss: 1.1728 - val_accuracy: 0.8080\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f52018c6c10>"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "validaition 데이터 정확도 : 83.9%으로 가장 정확도가 높음."
      ],
      "metadata": {
        "id": "XRIUmEl35Ax8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "FSzsFgtU5Uec"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JR2EP_WY5iLg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}